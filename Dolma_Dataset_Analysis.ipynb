{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPH//WvCYkc3QAYq8hvOL77",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soberbichler/DHd_Workshop_2026/blob/main/Dolma_Dataset_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urMVRGGarZ6d"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"allenai/dolma3_mix-5.5T-1125\", split=\"train\", streaming=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"allenai/dolma3_pool\", split=\"train\", streaming=True)\n",
        "\n",
        "doc = next(iter(dataset))\n",
        "metadata = doc['metadata']\n",
        "\n",
        "print(\"=\"*70)\n",
        "for key, value in metadata.items():\n",
        "    print(f\"{key:10s}: {str(value)[:100]}\")"
      ],
      "metadata": {
        "id": "tnSantcpvlSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "dataset = load_dataset(\"allenai/dolma3_pool\", split=\"train\", streaming=True)\n",
        "\n",
        "# Get first document\n",
        "doc = next(iter(dataset))\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"DOCUMENT EXAMPLE\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Show labels\n",
        "print(\"\\nLABELS (weborganizer metadata):\")\n",
        "print(\"-\" * 80)\n",
        "metadata = doc.get('metadata', {})\n",
        "weborganizer = metadata.get('weborganizer', {})\n",
        "print(json.dumps(weborganizer, indent=2, ensure_ascii=False))\n",
        "\n",
        "# Show content\n",
        "print(\"\\nCONTENT:\")\n",
        "print(\"-\" * 80)\n",
        "content = doc.get('text', '')\n",
        "# Show first 1000 characters\n",
        "print(content[:1000])\n",
        "if len(content) > 1000:\n",
        "    print(f\"\\n... (total length: {len(content)} characters)\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)"
      ],
      "metadata": {
        "id": "EZc6jH0fbNIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from urllib.parse import urlparse\n",
        "from collections import Counter\n",
        "\n",
        "dataset = load_dataset(\"allenai/dolma3_pool\", split=\"train\", streaming=True)\n",
        "\n",
        "MIN_CONFIDENCE = 0.5  # 50% or higher\n",
        "\n",
        "print(f\"Looking for documents with history_and_geography confidence > {MIN_CONFIDENCE}...\\n\")\n",
        "\n",
        "history_docs = []\n",
        "history_domains = Counter()\n",
        "\n",
        "for i, doc in enumerate(dataset.take(500000)):\n",
        "    metadata = doc.get('metadata', {})\n",
        "    weborganizer = metadata.get('weborganizer', {})\n",
        "\n",
        "    # Safety check: make sure weborganizer is a dict\n",
        "    if not isinstance(weborganizer, dict):\n",
        "        continue\n",
        "\n",
        "    # Get history confidence score (default to 0 if not found)\n",
        "    history_score = weborganizer.get('__label__history_and_geography', None)\n",
        "\n",
        "    # Skip if None or not a number\n",
        "    if history_score is None or not isinstance(history_score, (int, float)):\n",
        "        continue\n",
        "\n",
        "    if history_score > MIN_CONFIDENCE:\n",
        "        text = doc.get('text', '')\n",
        "        url = metadata.get('warc_url', '')\n",
        "        top_label = metadata.get('weborganizer_max', '').replace('__label__', '')\n",
        "\n",
        "        history_docs.append({\n",
        "            'index': i,\n",
        "            'score': history_score,\n",
        "            'top_label': top_label,\n",
        "            'url': url,\n",
        "            'text': text[:400],\n",
        "            'length': len(text)\n",
        "        })\n",
        "\n",
        "        # Track domains\n",
        "        if url:\n",
        "            domain = urlparse(url).netloc.replace('www.', '')\n",
        "            history_domains[domain] += 1\n",
        "\n",
        "print(f\"\\n\\n{'='*70}\")\n",
        "print(f\"HIGH-CONFIDENCE HISTORY DOCUMENTS (confidence > {MIN_CONFIDENCE})\")\n",
        "print('='*70)\n",
        "print(f\"Found: {len(history_docs):,} documents ({len(history_docs)/500000*100:.2f}%)\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"TOP DOMAINS\")\n",
        "print('='*70)\n",
        "for domain, count in history_domains.most_common(15):\n",
        "    print(f\"{domain:50s}: {count:3d}\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"WHAT WERE THESE LABELED AS? (top_label)\")\n",
        "print('='*70)\n",
        "top_labels = Counter([d['top_label'] for d in history_docs])\n",
        "for label, count in top_labels.most_common():\n",
        "    pct = count / len(history_docs) * 100 if history_docs else 0\n",
        "    print(f\"{label:40s}: {count:3d} ({pct:.1f}%)\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"EXAMPLES\")\n",
        "print('='*70)\n",
        "for i, doc in enumerate(history_docs[:10], 1):\n",
        "    print(f\"\\n{i}. Confidence: {doc['score']:.3f} | Labeled as: {doc['top_label']}\")\n",
        "    print(f\"   URL: {doc['url'][:70]}\")\n",
        "    print(f\"   Length: {doc['length']:,} chars\")\n",
        "    print(f\"   Text: {doc['text'][:250]}...\")\n",
        "    print(\"-\" * 70)"
      ],
      "metadata": {
        "id": "_PKphIApwGs2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}